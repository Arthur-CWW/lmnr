use super::ResponseResult;
use crate::{
    ch::{
        self,
        modifiers::GroupByInterval,
        spans::{get_time_bounds, IntMetricTimeValue},
        utils::hours_ago,
        Aggregation,
    },
    db::{
        self,
        events::EventWithTemplateName,
        modifiers::{DateRange, Filter, RelativeDateInterval},
        trace::{Span, Trace, TraceWithEvents},
        DB,
    },
};
use actix_web::{get, post, web, HttpResponse};
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use uuid::Uuid;

const DEFAULT_PAGE_SIZE: usize = 50;

#[derive(Deserialize, Debug)]
#[serde(rename_all = "camelCase")]
struct GetTracesQueryParams {
    /// page number starting from 0
    #[serde(default)]
    page_number: usize,
    page_size: Option<usize>,
    #[serde(default)]
    filter: Value,
    #[serde(default)]
    #[serde(flatten)]
    pub date_range: Option<DateRange>,
}

#[derive(Serialize)]
#[serde(rename_all = "camelCase")]
struct GetTracesResponse {
    total_entries: i64,
    traces: Vec<TraceWithEvents>,
    total_in_project: Option<i64>,
}

/// Get traces generated by Laminar tracing
#[get("traces")]
pub async fn get_traces(
    path: web::Path<Uuid>,
    db: web::Data<DB>,
    query_params: web::Query<GetTracesQueryParams>,
) -> ResponseResult {
    let project_id = path.into_inner();
    let query_params = query_params.into_inner();
    let limit = query_params.page_size.unwrap_or(DEFAULT_PAGE_SIZE);
    let offset = limit * (query_params.page_number);
    let filters = Filter::from_url_params(query_params.filter);
    let date_range = query_params.date_range;

    let traces = db::trace::get_traces(
        &db.pool,
        project_id,
        limit,
        offset,
        filters.clone(),
        date_range.as_ref(),
    )
    .await?;
    let total_entries =
        db::trace::count_traces(&db.pool, project_id, filters, date_range.as_ref()).await?;
    let total_in_project = if total_entries == 0 {
        Some(db::trace::count_all_traces_in_project(&db.pool, project_id).await?)
    } else {
        None
    };

    let response = GetTracesResponse {
        total_entries,
        traces,
        total_in_project,
    };

    Ok(HttpResponse::Ok().json(response))
}

#[get("traces/{trace_id}/trace-with-events")]
pub async fn get_trace_with_events(
    params: web::Path<(Uuid, Uuid)>,
    db: web::Data<DB>,
) -> ResponseResult {
    let (project_id, trace_id) = params.into_inner();

    let trace_with_events =
        db::trace::get_trace_with_events(&db.pool, trace_id, project_id).await?;

    Ok(HttpResponse::Ok().json(trace_with_events))
}

#[derive(Serialize)]
#[serde(rename_all = "camelCase")]
pub struct TraceWithSpanPreviews {
    #[serde(flatten)]
    pub trace: Trace,
    pub spans: Vec<Span>,
}

/// Get a single trace generated by Laminar tracing instrumentation
#[get("traces/{trace_id}")]
pub async fn get_single_trace(
    params: web::Path<(Uuid, Uuid)>,
    db: web::Data<DB>,
) -> ResponseResult {
    let (_project_id, trace_id) = params.into_inner();

    let trace = db::trace::get_single_trace(&db.pool, trace_id).await?;
    let span_previews = db::trace::get_span_previews(&db.pool, trace_id).await?;

    let trace_with_spans = TraceWithSpanPreviews {
        trace,
        spans: span_previews,
    };

    Ok(HttpResponse::Ok().json(trace_with_spans))
}

#[derive(Serialize)]
#[serde(rename_all = "camelCase")]
pub struct SpanWithEvents {
    #[serde(flatten)]
    pub span: Span,
    pub events: Vec<EventWithTemplateName>,
}

/// Get a single span generated by Laminar tracing instrumentation
#[get("spans/{span_id}")]
pub async fn get_single_span(params: web::Path<(Uuid, Uuid)>, db: web::Data<DB>) -> ResponseResult {
    let (_project_id, span_id) = params.into_inner();

    let span = db::trace::get_span(&db.pool, span_id).await?;
    let events = db::events::get_events_for_span(&db.pool, span_id).await?;

    let span_with_events = SpanWithEvents { span, events };

    Ok(HttpResponse::Ok().json(span_with_events))
}

#[get("trace-id-for-span/{span_id}")]
pub async fn get_trace_id_for_span(
    params: web::Path<(Uuid, Uuid)>,
    db: web::Data<DB>,
) -> ResponseResult {
    let (_project_id, span_id) = params.into_inner();

    // TODO: if querying the entire span with input and output is inefficient,
    // we can just query the trace_id in a separate db function
    let span = db::trace::get_span(&db.pool, span_id).await?;
    let trace_id = span.trace_id;

    Ok(HttpResponse::Ok().json(trace_id))
}

#[derive(Deserialize)]
#[serde(rename_all = "camelCase")]
enum TraceMetric {
    TraceCount,
    TraceLatencySeconds,
    TotalTokenCount,
    CostUsd,
}

#[derive(Deserialize)]
#[serde(rename_all = "camelCase")]
struct GetTraceMetricsParams {
    pub metric: TraceMetric,
    /// Total or average
    pub aggregation: Aggregation,
    /// Date range per page
    #[serde(default)]
    #[serde(flatten)]
    pub date_range: Option<DateRange>,
    /// Group by interval per page
    #[serde(default)]
    pub group_by_interval: GroupByInterval,
}

/// Get metrics for a single metric type (e.g. for average trace latency)
#[post("traces/metrics")]
pub async fn get_traces_metrics(
    params: web::Path<Uuid>,
    clickhouse: web::Data<clickhouse::Client>,
    req: web::Json<GetTraceMetricsParams>,
) -> ResponseResult {
    let project_id = params.into_inner();
    let clickhouse = clickhouse.into_inner().as_ref().clone();
    let req = req.into_inner();
    let metric = req.metric;
    let aggregation = req.aggregation;
    let date_range = req.date_range.as_ref();
    let group_by_interval = req.group_by_interval;

    // We expect the frontend to always provide a date range.
    // However, for smooth UX we default this to all time.
    let defaulted_range =
        date_range
            .cloned()
            .unwrap_or(DateRange::Relative(RelativeDateInterval {
                past_hours: "all".to_string(),
            }));

    match defaulted_range {
        DateRange::Relative(interval) => {
            let past_hours = if interval.past_hours == "all" {
                let time_bounds = get_time_bounds(clickhouse.clone(), project_id).await?;
                if time_bounds.min_time == 0 {
                    let values: Vec<IntMetricTimeValue> = vec![];
                    return Ok(HttpResponse::Ok().json(values));
                }
                let past_hours = hours_ago(time_bounds.min_time);
                // FIXME: This is definitely to do with the query, and this patch is likely not a solution.
                past_hours.max(48)
            } else {
                let past_hours: i64 = interval.past_hours.parse().map_err(|_| {
                    anyhow::anyhow!("Failed to parse past_hours as i64: {}", interval.past_hours)
                })?;

                past_hours
            };
            get_metrics_relative_time(
                clickhouse.clone(),
                metric,
                project_id,
                past_hours,
                group_by_interval,
                aggregation,
            )
            .await
        }
        DateRange::Absolute(interval) => {
            get_metrics_absolute_time(
                clickhouse.clone(),
                metric,
                project_id,
                interval.start_date,
                interval.end_date,
                group_by_interval,
                aggregation,
            )
            .await
        }
    }
}

async fn get_metrics_relative_time(
    clickhouse: clickhouse::Client,
    metric: TraceMetric,
    project_id: Uuid,
    past_hours: i64,
    group_by_interval: GroupByInterval,
    aggregation: Aggregation,
) -> ResponseResult {
    match metric {
        TraceMetric::TraceCount => match aggregation {
            Aggregation::Average => {
                return Err(anyhow::anyhow!(
                    "Average grouping is not supported for traceCount metric"
                )
                .into());
            }
            Aggregation::Total => {
                let values = ch::spans::get_total_trace_count_metrics_relative(
                    clickhouse,
                    group_by_interval,
                    project_id,
                    past_hours,
                )
                .await?;

                Ok(HttpResponse::Ok().json(values))
            }
        },
        TraceMetric::TraceLatencySeconds => match aggregation {
            Aggregation::Total => {
                return Err(anyhow::anyhow!(
                    "Total grouping is not supported for traceLatency metric"
                )
                .into());
            }
            Aggregation::Average => {
                let values = ch::spans::get_trace_latency_seconds_metrics_relative(
                    clickhouse,
                    group_by_interval,
                    project_id,
                    past_hours,
                    aggregation,
                )
                .await?;

                Ok(HttpResponse::Ok().json(values))
            }
        },
        TraceMetric::TotalTokenCount => match aggregation {
            Aggregation::Total => {
                let values = ch::spans::get_total_token_count_metrics_relative(
                    clickhouse,
                    group_by_interval,
                    project_id,
                    past_hours,
                    aggregation,
                )
                .await?;

                Ok(HttpResponse::Ok().json(values))
            }
            Aggregation::Average => {
                return Err(anyhow::anyhow!(
                    "Average grouping is not supported for totalTokenCount metric"
                )
                .into());
            }
        },
        TraceMetric::CostUsd => match aggregation {
            Aggregation::Total => {
                let values = ch::spans::get_cost_usd_metrics_relative(
                    clickhouse,
                    group_by_interval,
                    project_id,
                    past_hours,
                    aggregation,
                )
                .await?;

                Ok(HttpResponse::Ok().json(values))
            }
            Aggregation::Average => {
                return Err(anyhow::anyhow!(
                    "Average grouping is not supported for costUsd metric"
                )
                .into());
            }
        },
    }
}

async fn get_metrics_absolute_time(
    clickhouse: clickhouse::Client,
    metric: TraceMetric,
    project_id: Uuid,
    start_time: DateTime<Utc>,
    end_time: DateTime<Utc>,
    group_by_interval: GroupByInterval,
    aggregation: Aggregation,
) -> ResponseResult {
    match metric {
        TraceMetric::TraceCount => match aggregation {
            Aggregation::Average => {
                return Err(anyhow::anyhow!(
                    "Average grouping is not supported for traceCount metric"
                )
                .into());
            }
            Aggregation::Total => {
                let values = ch::spans::get_total_trace_count_metrics_absolute(
                    clickhouse,
                    group_by_interval,
                    project_id,
                    start_time,
                    end_time,
                )
                .await?;

                Ok(HttpResponse::Ok().json(values))
            }
        },
        TraceMetric::TraceLatencySeconds => match aggregation {
            Aggregation::Total => {
                return Err(anyhow::anyhow!(
                    "Total grouping is not supported for traceLatency metric"
                )
                .into());
            }
            Aggregation::Average => {
                let values = ch::spans::get_trace_latency_seconds_metrics_absolute(
                    clickhouse,
                    group_by_interval,
                    project_id,
                    start_time,
                    end_time,
                    aggregation,
                )
                .await?;

                Ok(HttpResponse::Ok().json(values))
            }
        },
        TraceMetric::TotalTokenCount => match aggregation {
            Aggregation::Total => {
                let values = ch::spans::get_total_token_count_metrics_absolute(
                    clickhouse,
                    group_by_interval,
                    project_id,
                    start_time,
                    end_time,
                    aggregation,
                )
                .await?;

                Ok(HttpResponse::Ok().json(values))
            }
            Aggregation::Average => {
                return Err(anyhow::anyhow!(
                    "Average grouping is not supported for totalTokenCount metric"
                )
                .into());
            }
        },
        TraceMetric::CostUsd => match aggregation {
            Aggregation::Total => {
                let values = ch::spans::get_cost_usd_metrics_absolute(
                    clickhouse,
                    group_by_interval,
                    project_id,
                    start_time,
                    end_time,
                    aggregation,
                )
                .await?;

                Ok(HttpResponse::Ok().json(values))
            }
            Aggregation::Average => {
                return Err(anyhow::anyhow!(
                    "Average grouping is not supported for costUsd metric"
                )
                .into());
            }
        },
    }
}
